{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large Language Models (LLMs) s√£o um componente central do LangChain. O LangChain n√£o atende seus pr√≥prios LLMs, mas fornece uma interface padr√£o para interagir com muitos LLMs diferentes. \\n\",\n",
    "    Para ser espec√≠fico, essa interface √© uma que recebe como entrada uma string e retorna uma string.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Existem muitos provedores de LLM (OpenAI, Cohere, Hugging Face, etc.) - a LLMclasse foi projetada para fornecer uma interface padr√£o para todos eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for√ßar o carregamento da sua chave de API que est√° no arquivo .env:\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI \n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamando a LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez uma jovem chamada Ana, que sempre foi fascinada pelo mundo da tecnologia e sempre sonhou em criar seus pr√≥prios programas. No entanto, ela nunca teve a oportunidade de aprender a programar, pois sua fam√≠lia n√£o tinha condi√ß√µes de pagar um curso.\\n\\nCerto dia, Ana descobriu que existiam diversos conte√∫dos gratuitos na internet que ensinavam a programar. Empolgada, ela come√ßou a devorar todo o conhecimento que encontrava, assistindo a tutoriais, lendo artigos e fazendo exerc√≠cios.\\n\\nNo in√≠cio, Ana ficou um pouco perdida com tantas linguagens e conceitos diferentes, mas ela n√£o desistiu. Ela criou uma rotina de estudos e se dedicava todos os dias, mesmo que por apenas algumas horas, a aprender a programar.\\n\\nCom o tempo, Ana come√ßou a entender os fundamentos da l√≥gica de programa√ß√£o e a se familiarizar com as linguagens de programa√ß√£o mais utilizadas no mercado. Ela tamb√©m descobriu que programar era muito mais do que escrever c√≥digos, era uma forma de solucionar problemas e'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = 'Conte uma hist√≥ria breve sobre a jornada de aprender a programar'\n",
    "llm.invoke(pergunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamando stream de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez uma jovem chamada Maria, que sempre foi fascinada por tecnologia e computadores. Ela sempre gostava de mexer no computador, mas nunca imaginou que um dia aprenderia a criar seus pr√≥prios programas.\n",
      "\n",
      "Um dia, Maria decidiu que era hora de aprender a programar. Ela pesquisou na internet e descobriu que existiam muitos cursos e tutoriais dispon√≠veis. Empolgada, ela escolheu um e come√ßou sua jornada.\n",
      "\n",
      "No in√≠cio, Maria ficou um pouco confusa com todas aquelas linhas de c√≥digos e comandos que pareciam uma l√≠ngua estrangeira. Mas ela n√£o desistiu, pois sabia que aprender a programar era um desafio que valia a pena.\n",
      "\n",
      "Com muita dedica√ß√£o e perseveran√ßa, Maria foi aprendendo os conceitos b√°sicos de programa√ß√£o e logo j√° estava criando seus primeiros programas simples. Cada vez que conseguia fazer seu c√≥digo funcionar corretamente, a sensa√ß√£o de realiza√ß√£o e orgulho era indescrit√≠vel.\n",
      "\n",
      "Mas a jornada de Maria estava apenas come√ßando, pois a programa√ß√£o √© um campo em const"
     ]
    }
   ],
   "source": [
    "# Um comportamento mais parecido com interface da OpenAI\n",
    "pergunta = 'Conte uma hist√≥ria breve sobre a jornada de aprender a programar'\n",
    "for trecho in llm.stream(pergunta):\n",
    "    print(trecho, end='')                    # O 'end='' controla que a cada print,seja em uma nova linha, fazendo com que cada print seja logo depois do anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamada Simult√¢neas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nO c√©u √© um conceito presente em diversas culturas e religi√µes que se refere a uma regi√£o ou plano elevado e divino, habitado por seres superiores e considerado o lugar de descanso e felicidade eterna ap√≥s a morte. Na maioria das cren√ßas, o c√©u √© visto como um lugar de paz, harmonia e plenitude, onde as almas dos justos e virtuosos podem alcan√ßar a vida ap√≥s a morte. Em algumas religi√µes orientais, o c√©u √© visto como um estado de ilumina√ß√£o e conex√£o com o divino, a ser alcan√ßado atrav√©s da pr√°tica espiritual. De forma geral, o c√©u √© associado a um lugar elevado e transcendente, onde a felicidade e a perfei√ß√£o s√£o alcan√ßadas.',\n",
       " '\\n\\nA terra √© o terceiro planeta do sistema solar, localizado a uma dist√¢ncia de aproximadamente 150 milh√µes de quil√¥metros do sol. √â o √∫nico planeta conhecido at√© o momento a abrigar vida, com uma grande diversidade de seres vivos, incluindo humanos. √â formada por uma camada s√≥lida externa, chamada de crosta, que cobre um n√∫cleo de ferro e n√≠quel fundido. A maior parte da superf√≠cie da terra √© coberta por √°gua, e tamb√©m possui ar, que √© essencial para a sustenta√ß√£o da vida. Al√©m disso, a terra possui um campo magn√©tico que a protege das part√≠culas solares e uma atmosfera que ajuda a regular a temperatura do planeta. ',\n",
       " '\\n\\nAs estrelas s√£o corpos celestes que emitem luz pr√≥pria devido √† fus√£o nuclear de elementos em seu n√∫cleo. Elas s√£o formadas por nuvens de g√°s e poeira que se contraem sob a for√ßa da gravidade, formando uma esfera de mat√©ria em equil√≠brio.\\n\\nAs estrelas s√£o respons√°veis por fornecer a maior parte da energia do universo, e s√£o essenciais para a exist√™ncia da vida em nosso planeta, j√° que fornecem calor e luz para a Terra. Elas tamb√©m s√£o importantes para a navega√ß√£o, j√° que sua posi√ß√£o no c√©u pode ser utilizada como refer√™ncia.\\n\\nExistem bilh√µes de estrelas em nossa gal√°xia, a Via L√°ctea, e bilh√µes de gal√°xias no universo, cada uma contendo milh√µes ou bilh√µes de estrelas. As estrelas variam em tamanho, cor, temperatura e brilho, e podem ser classificadas em diferentes tipos, como an√£s vermelhas, gigantes azuis, supergigantes vermelhas, entre outras.\\n\\nAl√©m disso, as estrelas podem']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas = [\n",
    "    'O que √© o c√©u?',\n",
    "    'O que √© a terra?',\n",
    "    'O que s√£o as estrelas'\n",
    "]\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "Os modelos de bate-papo s√£o um componente central do LangChain.\n",
    "\n",
    "Um modelo de bate-papo √© um modelo de linguagem que usa mensagens de bate-papo como entradas e retorna mensagens de bate-papo como sa√≠das (em oposi√ß√£o ao uso de texto simples).\n",
    "\n",
    "O LangChain tem integra√ß√µes com muitos provedores de modelos (OpenAI, Cohere, Hugging Face, etc.) e exp√µe uma interface padr√£o para interagir com todos esses modelos.\n",
    "\n",
    "O LangChain permite que voc√™ use modelos em modos de sincroniza√ß√£o, ass√≠ncrono, em lote e streaming, al√©m de fornecer outros recursos (por exemplo, cache) e muito mais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende, voc√™ est√° usando a matem√°tica convencional ou a matem√°tica das piadas? Na matem√°tica convencional, 1 + 1 √© igual a 2. Mas na matem√°tica das piadas, 1 + 1 pode ser igual a uma confus√£o, um aperto de m√£o ou at√© mesmo um par de meias! üòâ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 30, 'total_tokens': 110}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e4744d58-a44a-421e-b823-84a9bb186fd4-0', usage_metadata={'input_tokens': 30, 'output_tokens': 80, 'total_tokens': 110})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trabalhar com LangChain envolve flexibilidade, existem a sepera√ß√£o de bibliotecas para cada situa√ß√£o\n",
    "from langchain_core.messages import HumanMessage, SystemMessage     #Do LangChain Core, iremos usar: HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content='Voc√™ √© um assistente que conta piadas.'),       #SystemMessage determina todo o comportamento do meu LLM para aquele instante\n",
    "    HumanMessage(content='Quanto √© 1 + 1?')\n",
    "]\n",
    "\n",
    "chat.invoke(mensagens)                     #Aqui n√£o passamos mais um texto dentro do invoke, somente uma lista que contem mensagem diferentes: uma de sistema e outra humana\n",
    "\n",
    "                                           # Ir√° retornar IAMessage, porque foi a IA que respondeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso eu queira somente o content, salva em uma vari√°vel\n",
    "respostaIA = chat.invoke(mensagens) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Depende, voc√™ quer a resposta matem√°tica ou uma piada?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respostaIA.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 15,\n",
       "  'prompt_tokens': 30,\n",
       "  'total_tokens': 45},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retorno de meta data:\n",
    "respostaIA.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
